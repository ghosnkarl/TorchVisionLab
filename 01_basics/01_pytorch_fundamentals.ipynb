{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d81f5c1",
   "metadata": {},
   "source": [
    "# 01. PyTorch Fundamentals\n",
    "\n",
    "Welcome to PyTorch! Now that you understand what machine learning is, let's dive into the framework that will power your AI journey.\n",
    "\n",
    "By the end of this notebook, you'll understand:\n",
    "\n",
    "- **What PyTorch is** and why it's amazing for machine learning\n",
    "- **Tensors**: The fundamental building blocks of PyTorch\n",
    "- **Device management**: CPU vs GPU computation\n",
    "- **Basic tensor operations** and mathematics\n",
    "- **Advanced shape manipulation**: reshape, view, squeeze, unsqueeze, transpose, permute\n",
    "- **Tensor memory and performance**: contiguous tensors, cloning, and detaching\n",
    "- **Debugging tensor shapes**: common errors and how to fix them\n",
    "- **Practice exercises** to solidify your understanding\n",
    "\n",
    "Let's get started!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e64aa1",
   "metadata": {},
   "source": [
    "## What is PyTorch?\n",
    "\n",
    "PyTorch is like a **supercharged version of NumPy** designed specifically for machine learning. Think of it as:\n",
    "\n",
    "### NumPy + Superpowers = PyTorch\n",
    "\n",
    "| Feature                      | NumPy       | PyTorch        |\n",
    "| ---------------------------- | ----------- | -------------- |\n",
    "| **Multi-dimensional arrays** | ✅ Arrays   | ✅ Tensors     |\n",
    "| **Mathematical operations**  | ✅ Fast     | ✅ Even Faster |\n",
    "| **GPU acceleration**         | ❌ CPU only | ✅ GPU + CPU   |\n",
    "| **Automatic gradients**      | ❌ Manual   | ✅ Automatic   |\n",
    "| **Neural networks**          | Complex     | Easy           |\n",
    "| **Deep learning**            | Very hard   | Built-in       |\n",
    "\n",
    "### Key PyTorch Concepts:\n",
    "\n",
    "1. **Tensors**: Multi-dimensional arrays (like NumPy arrays, but better)\n",
    "2. **Autograd**: Automatic differentiation (computes gradients for you)\n",
    "3. **Neural Networks**: Pre-built components for deep learning\n",
    "4. **GPU Support**: Lightning-fast computation on graphics cards\n",
    "5. **Dynamic Graphs**: Flexible networks that can change during runtime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7cc484",
   "metadata": {},
   "source": [
    "## Setting Up PyTorch\n",
    "\n",
    "Let's start by importing PyTorch and checking our setup:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca3a3649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Setup Information\n",
      "========================================\n",
      "PyTorch version: 2.9.1\n",
      "\n",
      "Available Devices:\n",
      "CPU: ✅ Always available\n",
      "CUDA GPU: ❌ Not available (CPU only)\n",
      "MPS (Apple Silicon): ✅ Available\n",
      "\n",
      "Ready to learn PyTorch!\n"
     ]
    }
   ],
   "source": [
    "# Import PyTorch and related libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style for better-looking plots\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"PyTorch Setup Information\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check device availability\n",
    "print(\"\\nAvailable Devices:\")\n",
    "print(\"CPU: ✅ Always available\")\n",
    "\n",
    "# Check CUDA (NVIDIA GPU)\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA GPU: ✅ {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "else:\n",
    "    print(\"CUDA GPU: ❌ Not available (CPU only)\")\n",
    "\n",
    "# Check MPS (Apple Silicon GPU)\n",
    "if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    print(\"MPS (Apple Silicon): ✅ Available\")\n",
    "else:\n",
    "    print(\"MPS (Apple Silicon): ❌ Not available\")\n",
    "\n",
    "print(\"\\nReady to learn PyTorch!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a84c559",
   "metadata": {},
   "source": [
    "## Device Management: CPU vs GPU\n",
    "\n",
    "One of PyTorch's superpowers is the ability to run computations on different devices. Let's understand this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64684829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device: mps\n",
      "Device name: Apple Silicon GPU\n",
      "Device type: Apple GPU\n"
     ]
    }
   ],
   "source": [
    "# Let's determine the best device for our computations\n",
    "def get_device():\n",
    "    \"\"\"Get the best available device for PyTorch computations\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        device_name = torch.cuda.get_device_name(0)\n",
    "        device_type = \"NVIDIA GPU\"\n",
    "    elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        device_name = \"Apple Silicon GPU\"\n",
    "        device_type = \"Apple GPU\"\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        device_name = \"CPU\"\n",
    "        device_type = \"CPU\"\n",
    "\n",
    "    return device, device_name, device_type\n",
    "\n",
    "\n",
    "device, device_name, device_type = get_device()\n",
    "\n",
    "print(f\"Selected device: {device}\")\n",
    "print(f\"Device name: {device_name}\")\n",
    "print(f\"Device type: {device_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "231149fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample tensor: tensor([1, 2, 3, 4, 5], device='mps:0')\n",
      "Tensor device: mps:0\n",
      "Tensor dtype: torch.int64\n",
      "Tensor shape: torch.Size([5])\n",
      "\n",
      "Why Device Selection Matters:\n",
      "✅ Using Apple Silicon: Efficient and fast!\n",
      "Great balance of speed and power efficiency\n"
     ]
    }
   ],
   "source": [
    "# Create a simple tensor and move it to our device\n",
    "x = torch.tensor([1, 2, 3, 4, 5], device=device)\n",
    "print(f\"\\nSample tensor: {x}\")\n",
    "print(f\"Tensor device: {x.device}\")\n",
    "print(f\"Tensor dtype: {x.dtype}\")\n",
    "print(f\"Tensor shape: {x.shape}\")\n",
    "\n",
    "# Why device matters?\n",
    "print(\"\\nWhy Device Selection Matters:\")\n",
    "if device.type == \"cuda\":\n",
    "    print(\"✅ Using GPU: 10-100x faster for large computations!\")\n",
    "    print(\"Perfect for training neural networks\")\n",
    "elif device.type == \"mps\":\n",
    "    print(\"✅ Using Apple Silicon: Efficient and fast!\")\n",
    "    print(\"Great balance of speed and power efficiency\")\n",
    "else:\n",
    "    print(\"✅ Using CPU: Always works, good for learning\")\n",
    "    print(\"Perfect for understanding concepts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a3be76",
   "metadata": {},
   "source": [
    "## Understanding Tensors\n",
    "\n",
    "**Tensors are the foundation of PyTorch.** Think of them as multi-dimensional arrays with superpowers!\n",
    "\n",
    "### Tensor Dimensions Explained:\n",
    "\n",
    "- **0D Tensor (Scalar)**: A single number → `5`\n",
    "- **1D Tensor (Vector)**: A list of numbers → `[1, 2, 3]`\n",
    "- **2D Tensor (Matrix)**: A table of numbers → `[[1, 2], [3, 4]]`\n",
    "- **3D Tensor**: A cube of numbers → Used for RGB images\n",
    "- **4D Tensor**: Multiple cubes → Batch of images\n",
    "- **nD Tensor**: As many dimensions as you need!\n",
    "\n",
    "<video width=\"800\" controls autoplay muted loop>\n",
    "  <source src='../12_assets/understanding_tensors.mp4' type=\"video/mp4\">\n",
    "  Your browser does not support the video tag.\n",
    "</video>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbf1c04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0D Tensor (Scalar): 42\n",
      "Shape: torch.Size([]), Dimensions: 0\n"
     ]
    }
   ],
   "source": [
    "# 0D Tensor (Scalar)\n",
    "scalar = torch.tensor(42)\n",
    "print(f\"0D Tensor (Scalar): {scalar}\")\n",
    "print(f\"Shape: {scalar.shape}, Dimensions: {scalar.ndim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f59f942b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D Tensor (Vector): tensor([1, 2, 3, 4, 5])\n",
      "Shape: torch.Size([5]), Dimensions: 1\n"
     ]
    }
   ],
   "source": [
    "# 1D Tensor (Vector)\n",
    "vector = torch.tensor([1, 2, 3, 4, 5])\n",
    "print(f\"\\n1D Tensor (Vector): {vector}\")\n",
    "print(f\"Shape: {vector.shape}, Dimensions: {vector.ndim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "253b77b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2D Tensor (Matrix):\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "Shape: torch.Size([2, 3]), Dimensions: 2\n"
     ]
    }
   ],
   "source": [
    "# 2D Tensor (Matrix)\n",
    "matrix = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(f\"\\n2D Tensor (Matrix):\\n{matrix}\")\n",
    "print(f\"Shape: {matrix.shape}, Dimensions: {matrix.ndim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8772f52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3D Tensor:\n",
      "tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]])\n",
      "Shape: torch.Size([2, 2, 2]), Dimensions: 3\n"
     ]
    }
   ],
   "source": [
    "# 3D Tensor\n",
    "tensor_3d = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "print(f\"\\n3D Tensor:\\n{tensor_3d}\")\n",
    "print(f\"Shape: {tensor_3d.shape}, Dimensions: {tensor_3d.ndim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b09548b",
   "metadata": {},
   "source": [
    "## Creating Tensors\n",
    "\n",
    "There are many ways to create tensors in PyTorch. Let's explore the most common methods:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c92f32a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From list: tensor([1, 2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "# 1. From Python lists\n",
    "from_list = torch.tensor([1, 2, 3, 4, 5])\n",
    "print(f\"From list: {from_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75ac182c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From NumPy: tensor([1, 2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "# 2. From NumPy arrays\n",
    "numpy_array = np.array([1, 2, 3, 4, 5])\n",
    "from_numpy = torch.from_numpy(numpy_array)\n",
    "print(f\"From NumPy: {from_numpy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a249e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeros tensor (3x4):\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# 3. Filled with zeros\n",
    "zeros_tensor = torch.zeros(3, 4)  # 3x4 matrix of zeros\n",
    "print(f\"Zeros tensor (3x4):\\n{zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ddff7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones tensor (2x3):\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 4. Filled with ones\n",
    "ones_tensor = torch.ones(2, 3)  # 2x3 matrix of ones\n",
    "print(f\"Ones tensor (2x3):\\n{ones_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7690faa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random tensor (2x3):\n",
      "tensor([[0.7832, 0.4306, 0.0361],\n",
      "        [0.5041, 0.3105, 0.5953]])\n"
     ]
    }
   ],
   "source": [
    "# 5. Random numbers\n",
    "random_tensor = torch.rand(2, 3)  # Random numbers between 0 and 1\n",
    "print(f\"Random tensor (2x3):\\n{random_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7654bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random integers (3x3, 0-9):\n",
      "tensor([[5, 4, 0],\n",
      "        [6, 6, 2],\n",
      "        [8, 4, 9]])\n"
     ]
    }
   ],
   "source": [
    "# 6. Random integers\n",
    "random_int = torch.randint(0, 10, (3, 3))  # Random integers 0-9\n",
    "print(f\"Random integers (3x3, 0-9):\\n{random_int}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "12733b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear sequence (0 to 10, step 2): tensor([0, 2, 4, 6, 8])\n"
     ]
    }
   ],
   "source": [
    "# 7. Linear sequence\n",
    "linear_seq = torch.arange(0, 10, 2)  # 0, 2, 4, 6, 8\n",
    "print(f\"Linear sequence (0 to 10, step 2): {linear_seq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ddb80cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linspace (0 to 1, 5 points): tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "# 8. Linearly spaced\n",
    "linspace = torch.linspace(0, 1, 5)  # 5 evenly spaced numbers from 0 to 1\n",
    "print(f\"Linspace (0 to 1, 5 points): {linspace}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6203b415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template tensor:\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "\n",
      "Zeros like template:\n",
      "tensor([[0, 0],\n",
      "        [0, 0]])\n",
      "\n",
      "Ones like template:\n",
      "tensor([[1, 1],\n",
      "        [1, 1]])\n"
     ]
    }
   ],
   "source": [
    "# 9. Like another tensor (same shape)\n",
    "template = torch.tensor([[1, 2], [3, 4]])\n",
    "zeros_like = torch.zeros_like(template)\n",
    "ones_like = torch.ones_like(template)\n",
    "print(f\"Template tensor:\\n{template}\")\n",
    "print(f\"\\nZeros like template:\\n{zeros_like}\")\n",
    "print(f\"\\nOnes like template:\\n{ones_like}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406d6f0d",
   "metadata": {},
   "source": [
    "## Tensor Properties and Information\n",
    "\n",
    "Every tensor has important properties that tell us about its structure and data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6211e02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample tensor:\n",
      "tensor([[[ 1.5640e-01,  9.7927e-01, -5.1039e-01,  3.0801e+00,  2.3008e+00],\n",
      "         [-1.2666e+00,  1.8803e+00,  5.2863e-01,  9.8053e-01,  7.8732e-02],\n",
      "         [-3.2803e-02,  3.9363e-01, -6.9764e-01, -3.5430e-01,  8.3407e-01],\n",
      "         [ 2.0363e-01,  1.1565e+00, -5.7861e-01, -1.1036e+00,  4.9071e-01]],\n",
      "\n",
      "        [[-3.6829e-01,  3.2015e-01,  4.8171e-02, -4.4054e-01,  3.9004e-01],\n",
      "         [-3.3492e-01,  1.1768e+00,  5.6455e-01,  6.8401e-02, -1.5138e+00],\n",
      "         [ 1.1983e+00,  6.9467e-01, -4.3558e-01, -1.4403e+00,  1.4983e-01],\n",
      "         [ 1.0869e+00, -8.4305e-01, -8.3348e-01,  8.7935e-01,  3.6670e-01]],\n",
      "\n",
      "        [[ 3.2765e-01, -2.4384e-01, -6.6729e-01, -1.4888e-03, -1.1025e+00],\n",
      "         [-5.9479e-01, -1.9178e+00, -8.8494e-01,  7.5928e-01, -5.6905e-02],\n",
      "         [-1.8809e+00,  8.8587e-02,  9.1350e-02, -2.4446e-01,  6.1463e-01],\n",
      "         [-4.1297e-01,  5.7677e-01, -1.1181e+00,  5.7626e-01,  1.6109e+00]]])\n"
     ]
    }
   ],
   "source": [
    "# Create a sample tensor for demonstration\n",
    "sample_tensor = torch.randn(3, 4, 5)\n",
    "\n",
    "print(f\"\\nSample tensor:\\n{sample_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e3e7c1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Properties\n",
      "==============================\n",
      "Shape: torch.Size([3, 4, 5]) or torch.Size([3, 4, 5])\n",
      "Number of dimensions: 3\n",
      "Total number of elements: 60\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Requires gradient: False\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensor Properties\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "print(f\"Shape: {sample_tensor.shape} or {sample_tensor.size()}\")\n",
    "print(f\"Number of dimensions: {sample_tensor.ndim}\")\n",
    "print(f\"Total number of elements: {sample_tensor.numel()}\")\n",
    "print(f\"Data type: {sample_tensor.dtype}\")\n",
    "print(f\"Device: {sample_tensor.device}\")\n",
    "print(f\"Requires gradient: {sample_tensor.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3a06cc",
   "metadata": {},
   "source": [
    "**Shape Explanation:**\n",
    "\n",
    "- The first dimension (3) represents the number of matrices.\n",
    "- The second dimension (4) represents the number of rows in each matrix.\n",
    "- The third dimension (5) represents the number of columns in each row.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90c98d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common PyTorch Data Types:\n",
      "  torch.float32 (default): tensor([1., 2.]) (dtype: torch.float32)\n",
      "  torch.int64: tensor([1, 2]) (dtype: torch.int64)\n",
      "  torch.bool: tensor([ True, False]) (dtype: torch.bool)\n",
      "  torch.float16 (half precision): tensor([1., 2.], dtype=torch.float16) (dtype: torch.float16)\n"
     ]
    }
   ],
   "source": [
    "# Common data types\n",
    "print(\"Common PyTorch Data Types:\")\n",
    "types_demo = {\n",
    "    \"torch.float32 (default)\": torch.tensor([1.0, 2.0]),\n",
    "    \"torch.int64\": torch.tensor([1, 2]),\n",
    "    \"torch.bool\": torch.tensor([True, False]),\n",
    "    \"torch.float16 (half precision)\": torch.tensor([1.0, 2.0], dtype=torch.float16),\n",
    "}\n",
    "\n",
    "for name, tensor in types_demo.items():\n",
    "    print(f\"  {name}: {tensor} (dtype: {tensor.dtype})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcede4e",
   "metadata": {},
   "source": [
    "Pro Tip: Different data types use different amounts of memory!\n",
    "\n",
    "- float32 = 4 bytes per number\n",
    "- float16 = 2 bytes per number (saves memory!)\n",
    "- int64 = 8 bytes per number\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f512bdaf",
   "metadata": {},
   "source": [
    "## Basic Tensor Operations\n",
    "\n",
    "Now let's learn the fundamental operations you can perform with tensors:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "de3272a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor a: tensor([1, 2, 3, 4])\n",
      "Tensor b: tensor([5, 6, 7, 8])\n"
     ]
    }
   ],
   "source": [
    "# Create some sample tensors\n",
    "a = torch.tensor([1, 2, 3, 4])\n",
    "b = torch.tensor([5, 6, 7, 8])\n",
    "matrix_a = torch.tensor([[1, 2], [3, 4]])\n",
    "matrix_b = torch.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "print(f\"Tensor a: {a}\")\n",
    "print(f\"Tensor b: {b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bb5d69b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arithmetic Operations:\n",
      "\n",
      "Addition: tensor([ 6,  8, 10, 12])\n",
      "Subtraction: tensor([-4, -4, -4, -4])\n",
      "Multiplication: tensor([ 5, 12, 21, 32])\n",
      "Division: tensor([0.2000, 0.3333, 0.4286, 0.5000])\n",
      "Power: tensor([ 1,  4,  9, 16])\n"
     ]
    }
   ],
   "source": [
    "# Arithmetic operations\n",
    "print(\"Arithmetic Operations:\\n\")\n",
    "print(f\"Addition: {a + b}\")\n",
    "print(f\"Subtraction: {a - b}\")\n",
    "print(f\"Multiplication: {a * b}\")\n",
    "print(f\"Division: {a / b}\")\n",
    "print(f\"Power: {a ** 2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b995a488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Operations:\n",
      "\n",
      "Sum: 10\n",
      "Mean: 2.50\n",
      "Max: 4\n",
      "Min: 1\n",
      "Standard deviation: 1.29\n"
     ]
    }
   ],
   "source": [
    "print(\"Statistical Operations:\\n\")\n",
    "print(f\"Sum: {a.sum()}\")\n",
    "print(f\"Mean: {a.float().mean():.2f}\")\n",
    "print(f\"Max: {a.max()}\")\n",
    "print(f\"Min: {a.min()}\")\n",
    "print(f\"Standard deviation: {a.float().std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aca66c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Operations:\n",
      "\n",
      "Matrix A:\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "Matrix B:\n",
      "tensor([[5, 6],\n",
      "        [7, 8]])\n",
      "\n",
      "Matrix multiplication:\n",
      "tensor([[19, 22],\n",
      "        [43, 50]])\n",
      "\n",
      "Transpose of A:\n",
      "tensor([[1, 3],\n",
      "        [2, 4]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Matrix Operations:\\n\")\n",
    "print(f\"Matrix A:\\n{matrix_a}\")\n",
    "print(f\"Matrix B:\\n{matrix_b}\")\n",
    "print(f\"\\nMatrix multiplication:\\n{torch.matmul(matrix_a, matrix_b)}\")\n",
    "print(f\"\\nTranspose of A:\\n{matrix_a.T}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "899c4842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element-wise vs Matrix Multiplication:\n",
      "Element-wise (A * B):\n",
      "tensor([[ 5, 12],\n",
      "        [21, 32]])\n",
      "Matrix multiplication (A @ B):\n",
      "tensor([[19, 22],\n",
      "        [43, 50]])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise vs matrix multiplication\n",
    "print(\"Element-wise vs Matrix Multiplication:\")\n",
    "print(f\"Element-wise (A * B):\\n{matrix_a * matrix_b}\")\n",
    "print(f\"Matrix multiplication (A @ B):\\n{matrix_a @ matrix_b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6a1c2e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key Difference:\n",
      "   * : Element-wise (each element multiplied independently)\n",
      "   @ : Matrix multiplication (linear algebra rules)\n"
     ]
    }
   ],
   "source": [
    "print(\"Key Difference:\")\n",
    "print(\"   * : Element-wise (each element multiplied independently)\")\n",
    "print(\"   @ : Matrix multiplication (linear algebra rules)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ede459",
   "metadata": {},
   "source": [
    "<video width=\"800\" controls autoplay muted loop>\n",
    "  <source src='../12_assets/matrix_multiplication.mp4' type=\"video/mp4\">\n",
    "  Your browser does not support the video tag.\n",
    "</video>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26a00c0",
   "metadata": {},
   "source": [
    "## Tensor Shape Manipulation - Deep Dive\n",
    "\n",
    "Understanding how to manipulate tensor shapes is crucial for deep learning. Let's explore all the important operations in detail!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reshape_basics",
   "metadata": {},
   "source": [
    "### reshape() vs view() vs resize\\_()\n",
    "\n",
    "These three methods can change tensor shapes, but they have important differences:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "reshape_view",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
      "Shape: torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "# Create a simple tensor\n",
    "original = torch.arange(12)\n",
    "print(f\"Original tensor: {original}\")\n",
    "print(f\"Shape: {original.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "adbcbebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. reshape() - Always works, may return a copy\n",
    "reshaped = original.reshape(3, 4)\n",
    "reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6213555b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. view() - Faster but requires contiguous tensor\n",
    "viewed = original.view(3, 4)\n",
    "viewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3d982da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. resize_() - In-place operation, changes the original!\n",
    "to_resize = original.clone()\n",
    "to_resize.resize_(3, 4)\n",
    "to_resize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "squeeze_unsqueeze",
   "metadata": {},
   "source": [
    "### squeeze() and unsqueeze() - In Depth\n",
    "\n",
    "These operations add or remove dimensions of size 1. They're essential for matching shapes in neural networks!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "squeeze_examples",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor shape: torch.Size([1, 3, 1, 4, 1])\n",
      "Dimensions: 5\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor with extra dimensions\n",
    "tensor_with_ones = torch.rand(1, 3, 1, 4, 1)\n",
    "print(f\"Original tensor shape: {tensor_with_ones.shape}\")\n",
    "print(f\"Dimensions: {tensor_with_ones.ndim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8d5b5f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1, 4, 1]) -> torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "# squeeze() - Remove all dimensions of size 1\n",
    "squeezed = tensor_with_ones.squeeze()\n",
    "print(f\"{tensor_with_ones.shape} -> {squeezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "28c5fa2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1, 4, 1]) → torch.Size([3, 1, 4, 1])\n",
      "torch.Size([1, 3, 1, 4, 1]) → torch.Size([1, 3, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "# squeeze(dim) - Remove specific dimension\n",
    "squeeze_dim0 = tensor_with_ones.squeeze(0)  # Remove first dimension\n",
    "squeeze_dim2 = tensor_with_ones.squeeze(2)  # Remove third dimension\n",
    "print(f\"{tensor_with_ones.shape} → {squeeze_dim0.shape}\")\n",
    "print(f\"{tensor_with_ones.shape} → {squeeze_dim2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a51ef36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsqueeze(0): torch.Size([4]) → torch.Size([1, 4])\n",
      "unsqueeze(1): torch.Size([4]) → torch.Size([4, 1])\n",
      "unsqueeze(-1): torch.Size([4]) → torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "# unsqueeze() - Add dimension of size 1\n",
    "base = torch.tensor([1, 2, 3, 4])\n",
    "\n",
    "# Add dimension at different positions\n",
    "unsqueeze_0 = base.unsqueeze(0)  # Add at beginning\n",
    "unsqueeze_1 = base.unsqueeze(1)  # Add at end\n",
    "unsqueeze_neg = base.unsqueeze(-1)  # Add at end (negative indexing)\n",
    "\n",
    "print(f\"unsqueeze(0): {base.shape} → {unsqueeze_0.shape}\")\n",
    "print(f\"unsqueeze(1): {base.shape} → {unsqueeze_1.shape}\")\n",
    "print(f\"unsqueeze(-1): {base.shape} → {unsqueeze_neg.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d00618ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Practical Example: Batch Processing\n",
      "\n",
      "Single image shape: torch.Size([3, 224, 224])\n",
      "After unsqueeze(0): torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Practical example: Preparing for batch processing\n",
    "print(\"Practical Example: Batch Processing\\n\")\n",
    "single_image = torch.rand(3, 224, 224)  # Single image: [channels, height, width]\n",
    "print(f\"Single image shape: {single_image.shape}\")\n",
    "\n",
    "# Add batch dimension\n",
    "batched_image = single_image.unsqueeze(0)\n",
    "print(f\"After unsqueeze(0): {batched_image.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transpose_permute",
   "metadata": {},
   "source": [
    "### transpose() and permute()\n",
    "\n",
    "These operations rearrange dimensions, crucial for matching expected input shapes in neural networks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "transpose_examples",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample tensor\n",
    "tensor_3d = torch.rand(2, 3, 4)\n",
    "tensor_3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "90907586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transpose(0, 1): torch.Size([2, 3, 4]) → torch.Size([3, 2, 4])\n",
      "transpose(0, 2): torch.Size([2, 3, 4]) → torch.Size([4, 3, 2])\n",
      "transpose(1, 2): torch.Size([2, 3, 4]) → torch.Size([2, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "# transpose() - Swap two dimensions\n",
    "trans_0_1 = tensor_3d.transpose(0, 1)\n",
    "trans_0_2 = tensor_3d.transpose(0, 2)\n",
    "trans_1_2 = tensor_3d.transpose(1, 2)\n",
    "\n",
    "print(f\"transpose(0, 1): {tensor_3d.shape} → {trans_0_1.shape}\")\n",
    "print(f\"transpose(0, 2): {tensor_3d.shape} → {trans_0_2.shape}\")\n",
    "print(f\"transpose(1, 2): {tensor_3d.shape} → {trans_1_2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f9b82a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D Matrix: torch.Size([3, 4])\n",
      "matrix.T: torch.Size([4, 3])\n",
      "matrix.transpose(0, 1): torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "# .T shortcut for 2D tensors\n",
    "matrix = torch.rand(3, 4)\n",
    "print(f\"2D Matrix: {matrix.shape}\")\n",
    "print(f\"matrix.T: {matrix.T.shape}\")\n",
    "print(f\"matrix.transpose(0, 1): {matrix.transpose(0, 1).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "89c63162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: torch.Size([2, 3, 4])\n",
      "permute(2, 0, 1): torch.Size([2, 3, 4]) → torch.Size([4, 2, 3])\n",
      "permute(1, 2, 0): torch.Size([2, 3, 4]) → torch.Size([3, 4, 2])\n",
      "permute(2, 1, 0): torch.Size([2, 3, 4]) → torch.Size([4, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# permute() - Rearrange all dimensions at once\n",
    "print(f\"Original: {tensor_3d.shape}\")\n",
    "\n",
    "perm1 = tensor_3d.permute(2, 0, 1)  # [dim2, dim0, dim1]\n",
    "perm2 = tensor_3d.permute(1, 2, 0)  # [dim1, dim2, dim0]\n",
    "perm3 = tensor_3d.permute(2, 1, 0)  # [dim2, dim1, dim0] - reverse order\n",
    "\n",
    "print(f\"permute(2, 0, 1): {tensor_3d.shape} → {perm1.shape}\")\n",
    "print(f\"permute(1, 2, 0): {tensor_3d.shape} → {perm2.shape}\")\n",
    "print(f\"permute(2, 1, 0): {tensor_3d.shape} → {perm3.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1a9927e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Practical Example: Image Format Conversion\n",
      "\n",
      "PyTorch format (NCHW): torch.Size([32, 3, 224, 224])\n",
      "[batch, channels, height, width]\n",
      "\n",
      "Other format (NHWC): torch.Size([32, 224, 224, 3])\n",
      "[batch, height, width, channels]\n"
     ]
    }
   ],
   "source": [
    "# Practical example: Image format conversion\n",
    "print(\"Practical Example: Image Format Conversion\\n\")\n",
    "\n",
    "# PyTorch uses [batch, channels, height, width]\n",
    "pytorch_format = torch.rand(32, 3, 224, 224)\n",
    "print(f\"PyTorch format (NCHW): {pytorch_format.shape}\")\n",
    "print(\"[batch, channels, height, width]\\n\")\n",
    "\n",
    "# Some libraries use [batch, height, width, channels]\n",
    "other_format = pytorch_format.permute(0, 2, 3, 1)\n",
    "print(f\"Other format (NHWC): {other_format.shape}\")\n",
    "print(\"[batch, height, width, channels]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cab90d8",
   "metadata": {},
   "source": [
    "Key Differences between transpose() and permute():\n",
    "\n",
    "- transpose() is a specialized operation for 2D tensors (matrices) that swaps two dimensions.\n",
    "- permute() is a more general operation that can rearrange all dimensions of a tensor.\n",
    "\n",
    "Use transpose() for simple swaps, and permute() for more complex rearrangements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shape_errors",
   "metadata": {},
   "source": [
    "### Common Shape Errors and How to Fix Them\n",
    "\n",
    "Let's look at common shape-related errors you'll encounter and how to solve them!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "shape_error_examples",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor a: torch.Size([3, 4])\n",
      "Tensor b: torch.Size([3, 5])\n",
      "\n",
      "Trying a @ b...\n",
      "ERROR: mat1 and mat2 shapes cannot be multiplied (3x4 and 3x5)\n",
      "\n",
      "Solution: Transpose one of them\n",
      "a @ b_correct: torch.Size([3, 4]) @ torch.Size([4, 5]) = torch.Size([3, 5])\n",
      "Rule: (m, n) @ (n, p) = (m, p)\n"
     ]
    }
   ],
   "source": [
    "# Error 1: Matrix multiplication shape mismatch\n",
    "a = torch.rand(3, 4)\n",
    "b = torch.rand(3, 5)\n",
    "\n",
    "print(f\"Tensor a: {a.shape}\")\n",
    "print(f\"Tensor b: {b.shape}\")\n",
    "print(\"\\nTrying a @ b...\")\n",
    "try:\n",
    "    result = a @ b\n",
    "except RuntimeError as e:\n",
    "    print(f\"ERROR: {e}\")\n",
    "\n",
    "print(\"\\nSolution: Transpose one of them\")\n",
    "# result = a @ b.T  # Now shapes are (3,4) @ (5,3).T = (3,4) @ (3,5) - still wrong!\n",
    "\n",
    "# Correct way:\n",
    "b_correct = torch.rand(4, 5)\n",
    "result = a @ b_correct\n",
    "print(f\"a @ b_correct: {a.shape} @ {b_correct.shape} = {result.shape}\")\n",
    "print(\"Rule: (m, n) @ (n, p) = (m, p)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f0d2ae4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single sample shape: torch.Size([10])\n",
      "Neural networks expect: [batch_size, features]\n",
      "\n",
      "Solution 1 - unsqueeze(0): torch.Size([1, 10])\n",
      "Solution 2 - [None, :]: torch.Size([1, 10])\n",
      "Solution 3 - reshape(1, -1): torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "# Error 2: Missing batch dimension\n",
    "single_sample = torch.rand(10)  # Single sample with 10 features\n",
    "print(f\"Single sample shape: {single_sample.shape}\")\n",
    "print(\"Neural networks expect: [batch_size, features]\\n\")\n",
    "\n",
    "# Solution 1: unsqueeze\n",
    "batched_v1 = single_sample.unsqueeze(0)\n",
    "print(f\"Solution 1 - unsqueeze(0): {batched_v1.shape}\")\n",
    "\n",
    "# Solution 2: indexing\n",
    "batched_v2 = single_sample[None, :]  # or single_sample[np.newaxis, :]\n",
    "print(f\"Solution 2 - [None, :]: {batched_v2.shape}\")\n",
    "\n",
    "# Solution 3: reshape\n",
    "batched_v3 = single_sample.reshape(1, -1)\n",
    "print(f\"Solution 3 - reshape(1, -1): {batched_v3.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "939c6fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([32, 10])\n",
      "y shape: torch.Size([10])\n",
      "\n",
      "Want to add y to each sample in x\n",
      "x + y works! Result shape: torch.Size([32, 10])\n",
      "Broadcasting automatically expands y to (32, 10)\n",
      "\n",
      "If y has shape torch.Size([32]):\n",
      "ERROR: Shape mismatch!\n",
      "\n",
      "Solution: Make sure dimensions align\n",
      "x + y_correct.unsqueeze(1): torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "# Error 3: Dimension mismatch in operations\n",
    "x = torch.rand(32, 10)  # Batch of 32 samples, 10 features each\n",
    "y = torch.rand(10)  # 10 values\n",
    "\n",
    "print(f\"x shape: {x.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(\"\\nWant to add y to each sample in x\")\n",
    "\n",
    "# This works thanks to broadcasting!\n",
    "result = x + y\n",
    "print(f\"x + y works! Result shape: {result.shape}\")\n",
    "print(\"Broadcasting automatically expands y to (32, 10)\\n\")\n",
    "\n",
    "# But this won't work:\n",
    "y_wrong = torch.rand(32)\n",
    "print(f\"If y has shape {y_wrong.shape}:\")\n",
    "try:\n",
    "    result = x + y_wrong.unsqueeze(0)  # Try to add (1, 32) to (32, 10)\n",
    "except RuntimeError as e:\n",
    "    print(\"ERROR: Shape mismatch!\\n\")\n",
    "\n",
    "print(\"Solution: Make sure dimensions align\")\n",
    "y_correct = y_wrong.unsqueeze(1)  # (32,) → (32, 1)\n",
    "result = x + y_correct  # (32, 10) + (32, 1) broadcasts to (32, 10)\n",
    "print(f\"x + y_correct.unsqueeze(1): {result.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b4e0e4",
   "metadata": {},
   "source": [
    "## Indexing and Slicing - Advanced\n",
    "\n",
    "Just like NumPy arrays, you can select specific elements or parts of tensors. Let's explore basic and advanced indexing techniques:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "65fb8363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10, 11],\n",
       "        [12, 13, 14, 15, 16, 17],\n",
       "        [18, 19, 20, 21, 22, 23]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.arange(24).reshape(4, 6)  # 4x6 matrix\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaf02a0",
   "metadata": {},
   "source": [
    "### Basic Indexing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4e1f0a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([0, 1, 2, 3, 4, 5])\n",
      "Last row: tensor([18, 19, 20, 21, 22, 23])\n",
      "Element at position [1, 3]: 9\n",
      "First element of each row: tensor([ 0,  6, 12, 18])\n"
     ]
    }
   ],
   "source": [
    "print(f\"First row: {data[0]}\")\n",
    "print(f\"Last row: {data[-1]}\")\n",
    "print(f\"Element at position [1, 3]: {data[1, 3]}\")\n",
    "print(f\"First element of each row: {data[:, 0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23949b75",
   "metadata": {},
   "source": [
    "### Slicing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9f33d847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 2 rows:\n",
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "print(\"First 2 rows:\")\n",
    "print(data[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ef0bbc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 3 columns:\n",
      "tensor([[ 3,  4,  5],\n",
      "        [ 9, 10, 11],\n",
      "        [15, 16, 17],\n",
      "        [21, 22, 23]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last 3 columns:\")\n",
    "print(data[:, -3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1d48945c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Middle 2x3 submatrix:\n",
      "tensor([[ 8,  9, 10],\n",
      "        [14, 15, 16]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Middle 2x3 submatrix:\")\n",
    "print(data[1:3, 2:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7df0eff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every other row and column:\n",
      "tensor([[ 0,  2,  4],\n",
      "        [12, 14, 16]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Every other row and column:\")\n",
    "print(data[::2, ::2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a8244f",
   "metadata": {},
   "source": [
    "### Boolean Indexing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5d78a549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elements greater than 10: tensor([11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23])\n"
     ]
    }
   ],
   "source": [
    "mask = data > 10\n",
    "print(f\"Elements greater than 10: {data[mask]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d1545ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements > 10: 13\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of elements > 10: {(data > 10).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf2cb71",
   "metadata": {},
   "source": [
    "### Advanced Indexing Techniques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "advanced_indexing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 4, 5]),\n",
       " tensor([[[[0.7908, 0.1824, 0.7160, 0.9256, 0.2808],\n",
       "           [0.1740, 0.2295, 0.2597, 0.2145, 0.2552],\n",
       "           [0.7239, 0.4379, 0.0972, 0.3034, 0.2554],\n",
       "           [0.1236, 0.0605, 0.7103, 0.7975, 0.1538]],\n",
       " \n",
       "          [[0.2465, 0.5959, 0.2569, 0.8514, 0.4644],\n",
       "           [0.2938, 0.5732, 0.4248, 0.3513, 0.3371],\n",
       "           [0.1525, 0.2905, 0.6000, 0.1701, 0.0221],\n",
       "           [0.4289, 0.2826, 0.5970, 0.7360, 0.3822]],\n",
       " \n",
       "          [[0.3544, 0.8231, 0.8708, 0.5377, 0.0314],\n",
       "           [0.3406, 0.8524, 0.3711, 0.7938, 0.6055],\n",
       "           [0.8699, 0.4564, 0.1173, 0.4095, 0.9201],\n",
       "           [0.2632, 0.0147, 0.1753, 0.6964, 0.6919]]],\n",
       " \n",
       " \n",
       "         [[[0.1353, 0.5035, 0.8191, 0.6948, 0.6619],\n",
       "           [0.8941, 0.4973, 0.5123, 0.4088, 0.5292],\n",
       "           [0.9059, 0.6570, 0.1745, 0.5709, 0.5902],\n",
       "           [0.6171, 0.2286, 0.0893, 0.9714, 0.2501]],\n",
       " \n",
       "          [[0.7886, 0.5231, 0.9759, 0.1455, 0.9904],\n",
       "           [0.4901, 0.3624, 0.0062, 0.6042, 0.3608],\n",
       "           [0.8416, 0.8188, 0.4055, 0.5236, 0.9406],\n",
       "           [0.2398, 0.4868, 0.7689, 0.6078, 0.7592]],\n",
       " \n",
       "          [[0.1171, 0.1589, 0.2416, 0.5476, 0.5660],\n",
       "           [0.8492, 0.3395, 0.7410, 0.9941, 0.7217],\n",
       "           [0.5584, 0.7844, 0.1377, 0.1346, 0.2438],\n",
       "           [0.4705, 0.6661, 0.8162, 0.5602, 0.8287]]]]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ellipsis (...) indexing\n",
    "tensor_4d = torch.rand(2, 3, 4, 5)\n",
    "tensor_4d.shape, tensor_4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "12fe07e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 4]),\n",
       " tensor([[[[0.7908, 0.1824, 0.7160, 0.9256, 0.2808],\n",
       "           [0.1740, 0.2295, 0.2597, 0.2145, 0.2552],\n",
       "           [0.7239, 0.4379, 0.0972, 0.3034, 0.2554],\n",
       "           [0.1236, 0.0605, 0.7103, 0.7975, 0.1538]],\n",
       " \n",
       "          [[0.2465, 0.5959, 0.2569, 0.8514, 0.4644],\n",
       "           [0.2938, 0.5732, 0.4248, 0.3513, 0.3371],\n",
       "           [0.1525, 0.2905, 0.6000, 0.1701, 0.0221],\n",
       "           [0.4289, 0.2826, 0.5970, 0.7360, 0.3822]],\n",
       " \n",
       "          [[0.3544, 0.8231, 0.8708, 0.5377, 0.0314],\n",
       "           [0.3406, 0.8524, 0.3711, 0.7938, 0.6055],\n",
       "           [0.8699, 0.4564, 0.1173, 0.4095, 0.9201],\n",
       "           [0.2632, 0.0147, 0.1753, 0.6964, 0.6919]]],\n",
       " \n",
       " \n",
       "         [[[0.1353, 0.5035, 0.8191, 0.6948, 0.6619],\n",
       "           [0.8941, 0.4973, 0.5123, 0.4088, 0.5292],\n",
       "           [0.9059, 0.6570, 0.1745, 0.5709, 0.5902],\n",
       "           [0.6171, 0.2286, 0.0893, 0.9714, 0.2501]],\n",
       " \n",
       "          [[0.7886, 0.5231, 0.9759, 0.1455, 0.9904],\n",
       "           [0.4901, 0.3624, 0.0062, 0.6042, 0.3608],\n",
       "           [0.8416, 0.8188, 0.4055, 0.5236, 0.9406],\n",
       "           [0.2398, 0.4868, 0.7689, 0.6078, 0.7592]],\n",
       " \n",
       "          [[0.1171, 0.1589, 0.2416, 0.5476, 0.5660],\n",
       "           [0.8492, 0.3395, 0.7410, 0.9941, 0.7217],\n",
       "           [0.5584, 0.7844, 0.1377, 0.1346, 0.2438],\n",
       "           [0.4705, 0.6661, 0.8162, 0.5602, 0.8287]]]]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select all but last dimension\n",
    "result1 = tensor_4d[..., 0]  # Same as tensor_4d[:, :, :, 0]\n",
    "result1.shape, tensor_4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d2a37bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4]),\n",
       " tensor([[0.7908, 0.1740, 0.7239, 0.1236],\n",
       "         [0.2465, 0.2938, 0.1525, 0.4289],\n",
       "         [0.3544, 0.3406, 0.8699, 0.2632]]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select from first and last dimension\n",
    "result2 = tensor_4d[0, ..., 0]  # Same as tensor_4d[0, :, :, 0]\n",
    "result2.shape, result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "821e19b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1807, -0.1213, -0.0417, -0.1967],\n",
       "        [-1.9986, -0.3001, -0.4529, -0.7093],\n",
       "        [ 0.0046, -0.9967,  0.2855,  0.1409]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.where() - conditional selection\n",
    "x = torch.randn(3, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b4269fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0046, 0.0000, 0.2855, 0.1409]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace negative values with 0\n",
    "result = torch.where(x > 0, x, torch.tensor(0.0))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "74e2182a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2, 2, 2]), tensor([0, 2, 3]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get indices of elements satisfying condition\n",
    "indices = torch.where(x > 0)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2dc10048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: torch.Size([4, 5])\n",
      "Select rows [0, 2, 3]: torch.Size([3, 5])\n",
      "Select cols [0, 2, 3]: torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "# torch.index_select() - Select along a dimension\n",
    "tensor = torch.rand(4, 5)\n",
    "indices = torch.tensor([0, 2, 3])\n",
    "\n",
    "selected_rows = torch.index_select(tensor, dim=0, index=indices)\n",
    "selected_cols = torch.index_select(tensor, dim=1, index=indices)\n",
    "\n",
    "print(f\"Original: {tensor.shape}\")\n",
    "print(f\"Select rows [0, 2, 3]: {selected_rows.shape}\")\n",
    "print(f\"Select cols [0, 2, 3]: {selected_cols.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8b9475fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([3, 4])\n",
      "Selected (x > 0): tensor([0.7016])\n",
      "Selected shape: torch.Size([1]) (flattened!)\n"
     ]
    }
   ],
   "source": [
    "# torch.masked_select() - Select using boolean mask\n",
    "x = torch.randn(3, 4)\n",
    "mask = x > 0\n",
    "selected = torch.masked_select(x, mask)\n",
    "print(f\"Original shape: {x.shape}\")\n",
    "print(f\"Selected (x > 0): {selected}\")\n",
    "print(f\"Selected shape: {selected.shape} (flattened!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practice_exercises",
   "metadata": {},
   "source": [
    "## Practice Exercises\n",
    "\n",
    "Test your understanding with these exercises! Try to solve them before looking at the solutions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2d9c97",
   "metadata": {},
   "source": [
    "### Exercise 1: Shape Manipulation\n",
    "\n",
    "Given a tensor of shape (10, 20, 30):\n",
    "\n",
    "1. Add a batch dimension at the beginning\n",
    "2. Swap the last two dimensions\n",
    "3. Flatten the last two dimensions\n",
    "4. Remove all dimensions of size 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "exercise1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting shape: torch.Size([10, 20, 30])\n",
      "\n",
      "Solutions:\n",
      "1. Add batch dimension: torch.Size([1, 10, 20, 30])\n",
      "2. Swap last two dims: torch.Size([10, 30, 20])\n",
      "3. Flatten last two dims: torch.Size([10, 600])\n",
      "4. After squeeze: torch.Size([1, 10, 1, 20, 30]) → torch.Size([10, 20, 30])\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "x = torch.rand(10, 20, 30)\n",
    "print(f\"Starting shape: {x.shape}\\n\")\n",
    "\n",
    "# Solution\n",
    "print(\"Solutions:\")\n",
    "step1 = x.unsqueeze(0)\n",
    "print(f\"1. Add batch dimension: {step1.shape}\")\n",
    "\n",
    "step2 = x.transpose(-2, -1)  # or transpose(1, 2)\n",
    "print(f\"2. Swap last two dims: {step2.shape}\")\n",
    "\n",
    "step3 = x.flatten(start_dim=-2)  # or reshape(10, -1)\n",
    "print(f\"3. Flatten last two dims: {step3.shape}\")\n",
    "\n",
    "x_with_ones = x.unsqueeze(0).unsqueeze(2)\n",
    "step4 = x_with_ones.squeeze()\n",
    "print(f\"4. After squeeze: {x_with_ones.shape} → {step4.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7bf451",
   "metadata": {},
   "source": [
    "### Exercise 2: Broadcasting Challenge\n",
    "\n",
    "Given:\n",
    "\n",
    "- tensor A with shape (32, 1, 10)\n",
    "- tensor B with shape (1, 5, 10)\n",
    "\n",
    "Perform element-wise multiplication. What will the output shape be?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "exercise2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution:\n",
      "A shape: torch.Size([32, 1, 10])\n",
      "B shape: torch.Size([1, 5, 10])\n",
      "Result shape: torch.Size([32, 5, 10])\n",
      "\n",
      "Explanation: Broadcasting aligns dimensions from right to left\n",
      "A: (32, 1, 10) → broadcasts to (32, 5, 10)\n",
      "B: ( 1, 5, 10) → broadcasts to (32, 5, 10)\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "A = torch.rand(32, 1, 10)\n",
    "B = torch.rand(1, 5, 10)\n",
    "\n",
    "# Solution\n",
    "print(\"Solution:\")\n",
    "result = A * B\n",
    "print(f\"A shape: {A.shape}\")\n",
    "print(f\"B shape: {B.shape}\")\n",
    "print(f\"Result shape: {result.shape}\")\n",
    "print(\"\\nExplanation: Broadcasting aligns dimensions from right to left\")\n",
    "print(\"A: (32, 1, 10) → broadcasts to (32, 5, 10)\")\n",
    "print(\"B: ( 1, 5, 10) → broadcasts to (32, 5, 10)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903d67bd",
   "metadata": {},
   "source": [
    "### Exercise 3: Matrix Multiplication Challenge\n",
    "\n",
    "You have:\n",
    "\n",
    "- Batch of images: (64, 3, 224, 224)\n",
    "- Weight matrix: (50176, 1000)\n",
    "\n",
    "Reshape images and multiply to get (64, 1000) output.\n",
    "Note: 50176 = 3 _ 224 _ 224\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "exercise3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution:\n",
      "Images shape: torch.Size([64, 3, 224, 224])\n",
      "Weights shape: torch.Size([50176, 1000])\n",
      "\n",
      "After flattening: torch.Size([64, 150528])\n",
      "\n",
      "This is exactly what happens in neural networks!\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "images = torch.rand(64, 3, 224, 224)\n",
    "weights = torch.rand(50176, 1000)\n",
    "\n",
    "# Solution\n",
    "print(\"Solution:\")\n",
    "print(f\"Images shape: {images.shape}\")\n",
    "print(f\"Weights shape: {weights.shape}\")\n",
    "\n",
    "# Step 1: Flatten each image\n",
    "images_flat = images.flatten(start_dim=1)  # Keep batch dimension\n",
    "print(f\"\\nAfter flattening: {images_flat.shape}\")\n",
    "\n",
    "# Step 2: Matrix multiplication\n",
    "# output = images_flat @ weights\n",
    "# print(f\"After matmul: {output.shape}\")\n",
    "\n",
    "print(\"\\nThis is exactly what happens in neural networks!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6ed738",
   "metadata": {},
   "source": [
    "### Exercise 4: Memory Efficiency\n",
    "\n",
    "Create a function that checks if an operation created a view or copy.\n",
    "Test it with: transpose, reshape, clone, and contiguous.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "exercise4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor shape: torch.Size([3, 4])\n",
      "\n",
      "transpose      : VIEW (shares memory)\n",
      "reshape        : VIEW (shares memory)\n",
      "clone          : COPY (new memory)\n",
      "contiguous     : COPY (new memory)\n"
     ]
    }
   ],
   "source": [
    "def shares_memory(tensor1, tensor2):\n",
    "    \"\"\"Check if two tensors share memory\"\"\"\n",
    "    return tensor1.storage().data_ptr() == tensor2.storage().data_ptr()\n",
    "\n",
    "\n",
    "# Solution\n",
    "x = torch.arange(12).reshape(3, 4)\n",
    "print(f\"Original tensor shape: {x.shape}\\n\")\n",
    "\n",
    "operations = [\n",
    "    (\"transpose\", x.transpose(0, 1)),\n",
    "    (\"reshape\", x.reshape(2, 6)),\n",
    "    (\"clone\", x.clone()),\n",
    "    (\"contiguous\", x.transpose(0, 1).contiguous()),\n",
    "]\n",
    "\n",
    "for name, result in operations:\n",
    "    is_view = shares_memory(x, result)\n",
    "    print(f\"{name:15s}: {'VIEW (shares memory)' if is_view else 'COPY (new memory)'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2330f58f",
   "metadata": {},
   "source": [
    "### Exercise 5: Real-World Scenario\n",
    "\n",
    "You're building an image classifier that processes batches of images.\n",
    "\n",
    "Task: Write a function that:\n",
    "\n",
    "1. Takes a single image (3, 224, 224)\n",
    "2. Normalizes it to [-1, 1] range\n",
    "3. Adds batch dimension\n",
    "4. Returns it ready for model input (1, 3, 224, 224)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "exercise5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([3, 224, 224])\n",
      "Input range: [0.000, 1.000]\n",
      "\n",
      "Output shape: torch.Size([1, 3, 224, 224])\n",
      "Output range: [-1.000, 1.000]\n",
      "\n",
      "Perfect! Ready for model input.\n"
     ]
    }
   ],
   "source": [
    "def prepare_image(image):\n",
    "    \"\"\"\n",
    "    Prepare a single image for model input\n",
    "\n",
    "    Args:\n",
    "        image: Tensor of shape (3, 224, 224) with values in [0, 1]\n",
    "\n",
    "    Returns:\n",
    "        Tensor of shape (1, 3, 224, 224) with values in [-1, 1]\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    # Step 1: Normalize to [-1, 1]\n",
    "    normalized = image * 2 - 1\n",
    "\n",
    "    # Step 2: Add batch dimension\n",
    "    batched = normalized.unsqueeze(0)\n",
    "\n",
    "    return batched\n",
    "\n",
    "\n",
    "# Test the function\n",
    "test_image = torch.rand(3, 224, 224)  # Random image in [0, 1]\n",
    "print(f\"Input shape: {test_image.shape}\")\n",
    "print(f\"Input range: [{test_image.min():.3f}, {test_image.max():.3f}]\")\n",
    "\n",
    "prepared = prepare_image(test_image)\n",
    "print(f\"\\nOutput shape: {prepared.shape}\")\n",
    "print(f\"Output range: [{prepared.min():.3f}, {prepared.max():.3f}]\")\n",
    "print(\"\\nPerfect! Ready for model input.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d097a977",
   "metadata": {},
   "source": [
    "## Summary & What's Next\n",
    "\n",
    "Congratulations! You've mastered the fundamentals of PyTorch!\n",
    "\n",
    "### What You Learned:\n",
    "\n",
    "1. **PyTorch Basics**:\n",
    "\n",
    "   - What PyTorch is and why it's powerful\n",
    "   - Device management (CPU vs GPU)\n",
    "   - Setting up your environment\n",
    "\n",
    "2. **Tensors Mastery**:\n",
    "\n",
    "   - Creating tensors in multiple ways\n",
    "   - Understanding tensor properties (shape, dtype, device)\n",
    "   - Basic operations and mathematical functions\n",
    "   - Advanced shape manipulation (reshape, view, squeeze, unsqueeze, transpose, permute)\n",
    "   - Indexing and slicing\n",
    "\n",
    "3. **Memory and Performance**:\n",
    "\n",
    "   - Contiguous vs non-contiguous tensors\n",
    "   - When copying happens\n",
    "   - clone() vs detach() vs copy\\_()\n",
    "   - Memory-efficient operations\n",
    "\n",
    "4. **Debugging Skills**:\n",
    "\n",
    "   - Common shape errors and solutions\n",
    "   - Tensor inspection techniques\n",
    "   - Comprehensive troubleshooting guide\n",
    "\n",
    "5. **Random Numbers**:\n",
    "   - Different distributions (uniform, normal, etc.)\n",
    "   - Setting seeds for reproducibility\n",
    "   - Why randomness matters in ML\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "Now that you have a solid foundation in PyTorch tensors, you're ready to:\n",
    "\n",
    "1. **Build your first neural network** - See the next notebook for a comprehensive introduction to neural networks\n",
    "2. **Learn about automatic differentiation** with PyTorch's autograd\n",
    "3. **Explore advanced tensor operations** and linear algebra\n",
    "4. **Dive into deep learning architectures**\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "- **Tensors are the foundation** of everything in PyTorch\n",
    "- **Understanding shapes** is crucial - when in doubt, print the shape!\n",
    "- **Device management** is important for performance\n",
    "- **Memory efficiency** matters - use views when possible\n",
    "- **Debugging systematically** saves time - inspect tensors thoroughly\n",
    "\n",
    "**Ready to build neural networks? Continue to the next notebook!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46s8a2g35ik",
   "metadata": {},
   "source": [
    "## Additional Resources for Going Deeper\n",
    "\n",
    "Want to master PyTorch fundamentals? Here are curated resources to help you dive deeper into tensors, operations, and deep learning with PyTorch.\n",
    "\n",
    "### 📺 Video Tutorials & Courses\n",
    "\n",
    "**1. Zero to Mastery - Learn PyTorch for Deep Learning**\n",
    "\n",
    "- 25 hours of beginner-friendly material available on YouTube\n",
    "- All course materials available for free as an online book\n",
    "- Code examples in Google Colab notebooks\n",
    "- [Website](https://www.learnpytorch.io/) | [GitHub Repository](https://github.com/mrdbourke/pytorch-deep-learning)\n",
    "\n",
    "**2. Official PyTorch YouTube Series**\n",
    "\n",
    "- Self-contained examples introducing fundamental PyTorch concepts\n",
    "- Follows the official PyTorch Beginner Series\n",
    "- [Tutorial Documentation](https://docs.pytorch.org/tutorials/beginner/introyt/)\n",
    "\n",
    "### 📚 Articles & Written Guides\n",
    "\n",
    "**1. A Beginner's Guide to Tensor Operations in PyTorch (Medium)**\n",
    "\n",
    "- Complete walkthrough of tensor initialization, operations, indexing, and reshaping\n",
    "- Covers broadcasting and GPU management\n",
    "- [Read Article](https://medium.com/@piyushkashyap045/a-beginners-guide-to-tensor-operations-in-pytorch-learn-the-basics-and-beyond-c32d53b28292)\n",
    "\n",
    "**2. How to Learn PyTorch From Scratch in 2026 (DataCamp)**\n",
    "\n",
    "- Step-by-step tutorials with practical tips\n",
    "- 8-week learning plan to master deep learning\n",
    "- [Read Guide](https://www.datacamp.com/blog/how-to-learn-pytorch)\n",
    "\n",
    "**3. PyTorch in One Hour (Sebastian Raschka, PhD)**\n",
    "\n",
    "- Fast-paced guide from tensors to training neural networks on multiple GPUs\n",
    "- Perfect for those who want a quick but comprehensive overview\n",
    "- [Read Article](https://sebastianraschka.com/teaching/pytorch-1h/)\n",
    "\n",
    "**4. Tensor Operations in PyTorch (GeeksforGeeks)**\n",
    "\n",
    "- Comprehensive coverage of tensor operations\n",
    "- Great for quick reference\n",
    "- [Read Article](https://www.geeksforgeeks.org/tensor-operations-in-pytorch/)\n",
    "\n",
    "**5. Manipulating Tensors in PyTorch (MachineLearningMastery.com)**\n",
    "\n",
    "- Practical guide to tensor manipulation\n",
    "- [Read Article](https://machinelearningmastery.com/manipulating-tensors-in-pytorch/)\n",
    "\n",
    "### 🔧 Official Documentation\n",
    "\n",
    "**1. PyTorch Tensors Tutorial**\n",
    "\n",
    "- Over 1,200 tensor operations comprehensively described\n",
    "- Includes arithmetic, linear algebra, matrix manipulation, sampling, and more\n",
    "- [Official Documentation](https://docs.pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html)\n",
    "\n",
    "**2. Introduction to PyTorch Tensors (Deep Dive)**\n",
    "\n",
    "- Deeper exploration of PyTorch tensors\n",
    "- [Official Tutorial](https://docs.pytorch.org/tutorials/beginner/introyt/tensors_deeper_tutorial.html)\n",
    "\n",
    "**3. Broadcasting Semantics**\n",
    "\n",
    "- Essential reading for understanding tensor shape compatibility\n",
    "- Explains broadcasting rules and behavior in detail\n",
    "- [Official Documentation](https://docs.pytorch.org/docs/stable/notes/broadcasting.html)\n",
    "\n",
    "**4. Learn the Basics - PyTorch Tutorial Series**\n",
    "\n",
    "- Official quickstart guide covering tensors, datasets, models, and more\n",
    "- [Start Learning](https://docs.pytorch.org/tutorials/beginner/basics/intro.html)\n",
    "\n",
    "### 🎓 Interactive Courses (Free & Paid)\n",
    "\n",
    "**1. DataCamp - Introduction to Deep Learning with PyTorch**\n",
    "\n",
    "- Build neural networks and tackle classification/regression problems\n",
    "- Interactive coding environment\n",
    "- [Start Course](https://www.datacamp.com/courses/introduction-to-deep-learning-with-pytorch)\n",
    "\n",
    "**2. Coursera - Deep Neural Networks with PyTorch**\n",
    "\n",
    "- Introduction to Neural Networks and PyTorch\n",
    "- Free to audit\n",
    "- [Course Link](https://www.coursera.org/learn/deep-neural-networks-with-pytorch)\n",
    "\n",
    "**3. Scaler - PyTorch for Deep Learning Certification (FREE)**\n",
    "\n",
    "- Free certification course designed for beginners\n",
    "- [Enroll Now](https://www.scaler.com/topics/course/pytorch-for-deep-learning-free-course/)\n",
    "\n",
    "### 💡 Practice Resources\n",
    "\n",
    "**1. CodingNomads - Broadcasting with PyTorch**\n",
    "\n",
    "- Interactive tutorials on broadcasting\n",
    "- [Learn Broadcasting](https://codingnomads.com/broadcasting-with-pytorch)\n",
    "\n",
    "**2. The PyTorch Book - Broadcasting Chapter**\n",
    "\n",
    "- Detailed examples and explanations\n",
    "- [Read Chapter](https://aayushmnit.com/pytorch_book/nbs/3_broadcasting.html)\n",
    "\n",
    "### 🚀 Next Steps\n",
    "\n",
    "After mastering the fundamentals:\n",
    "\n",
    "1. Move to the next notebook in this course for neural networks\n",
    "2. Build small projects to practice (MNIST classifier, image recognition, etc.)\n",
    "3. Join the PyTorch community forums\n",
    "4. Contribute to open-source PyTorch projects\n",
    "5. Follow PyTorch on social media for latest updates\n",
    "\n",
    "**Pro Tip**: The best way to learn is by doing! Try implementing the concepts you've learned in this notebook using the resources above, then build your own projects.\n",
    "\n",
    "Happy Learning! 🔥\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TorchVisionLab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
